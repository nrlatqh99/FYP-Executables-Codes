{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caed1555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Text preprocessing\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import string\n",
    "# Feature engineering/ML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5716a8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Volume_No</th>\n",
       "      <th>Chapter_No</th>\n",
       "      <th>Hadith_No</th>\n",
       "      <th>Chapter</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>Narrated by 'Umar bin Al-Khattab:  I heard All...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>Narrated by 'Aisha: (the mother of the faithfu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>Narrated by 'Aisha: (the mother of the faithfu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>Narrated by Said bin Jubair: Ibn 'Abbas in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>Narrated by Ibn 'Abbas: Allah's Apostle was th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>216</td>\n",
       "      <td>Shortening Prayers (At-Taqseer)</td>\n",
       "      <td>Narrated by 'Imran bin Husain (who had piles):...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>217</td>\n",
       "      <td>Shortening Prayers (At-Taqseer)</td>\n",
       "      <td>Narrated by 'Abdullah bin Buraida: 'Imran bin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>218</td>\n",
       "      <td>Shortening Prayers (At-Taqseer)</td>\n",
       "      <td>Narrated by 'Imran bin Husain had piles, so I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>219</td>\n",
       "      <td>Shortening Prayers (At-Taqseer)</td>\n",
       "      <td>Narrated by 'Aisha (the mother of the faithful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>220</td>\n",
       "      <td>Shortening Prayers (At-Taqseer)</td>\n",
       "      <td>Narrated by 'Aisha (the mother of the faithful...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1055 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Source  Volume_No  Chapter_No  Hadith_No  \\\n",
       "0     Sahih Bukhari          1           1          1   \n",
       "1     Sahih Bukhari          1           1          2   \n",
       "2     Sahih Bukhari          1           1          3   \n",
       "3     Sahih Bukhari          1           1          4   \n",
       "4     Sahih Bukhari          1           1          5   \n",
       "...             ...        ...         ...        ...   \n",
       "1050  Sahih Bukhari          2          20        216   \n",
       "1051  Sahih Bukhari          2          20        217   \n",
       "1052  Sahih Bukhari          2          20        218   \n",
       "1053  Sahih Bukhari          2          20        219   \n",
       "1054  Sahih Bukhari          2          20        220   \n",
       "\n",
       "                              Chapter  \\\n",
       "0                          Revelation   \n",
       "1                          Revelation   \n",
       "2                          Revelation   \n",
       "3                          Revelation   \n",
       "4                          Revelation   \n",
       "...                               ...   \n",
       "1050  Shortening Prayers (At-Taqseer)   \n",
       "1051  Shortening Prayers (At-Taqseer)   \n",
       "1052  Shortening Prayers (At-Taqseer)   \n",
       "1053  Shortening Prayers (At-Taqseer)   \n",
       "1054  Shortening Prayers (At-Taqseer)   \n",
       "\n",
       "                                                   Text  \n",
       "0     Narrated by 'Umar bin Al-Khattab:  I heard All...  \n",
       "1     Narrated by 'Aisha: (the mother of the faithfu...  \n",
       "2     Narrated by 'Aisha: (the mother of the faithfu...  \n",
       "3     Narrated by Said bin Jubair: Ibn 'Abbas in the...  \n",
       "4     Narrated by Ibn 'Abbas: Allah's Apostle was th...  \n",
       "...                                                 ...  \n",
       "1050  Narrated by 'Imran bin Husain (who had piles):...  \n",
       "1051  Narrated by 'Abdullah bin Buraida: 'Imran bin ...  \n",
       "1052  Narrated by 'Imran bin Husain had piles, so I ...  \n",
       "1053  Narrated by 'Aisha (the mother of the faithful...  \n",
       "1054  Narrated by 'Aisha (the mother of the faithful...  \n",
       "\n",
       "[1055 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\Acer\\anaconda3\\activity\\Sahih Bukhari Dataset (20 Chapters).csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39d7428c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Volume_No</th>\n",
       "      <th>Chapter_No</th>\n",
       "      <th>Hadith_No</th>\n",
       "      <th>Chapter</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>['narrated', 'by', \"'umar\", 'bin', 'al-khattab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>['narrated', 'by', \"'aisha\", ':', '(', 'the', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>['narrated', 'by', \"'aisha\", ':', '(', 'the', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>['narrated', 'by', 'said', 'bin', 'jubair', ':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>['narrated', 'by', 'ibn', \"'abbas\", ':', 'alla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Source  Volume_No  Chapter_No  Hadith_No     Chapter  \\\n",
       "0  Sahih Bukhari          1           1          1  Revelation   \n",
       "1  Sahih Bukhari          1           1          2  Revelation   \n",
       "2  Sahih Bukhari          1           1          3  Revelation   \n",
       "3  Sahih Bukhari          1           1          4  Revelation   \n",
       "4  Sahih Bukhari          1           1          5  Revelation   \n",
       "\n",
       "                                                Text  \n",
       "0  ['narrated', 'by', \"'umar\", 'bin', 'al-khattab...  \n",
       "1  ['narrated', 'by', \"'aisha\", ':', '(', 'the', ...  \n",
       "2  ['narrated', 'by', \"'aisha\", ':', '(', 'the', ...  \n",
       "3  ['narrated', 'by', 'said', 'bin', 'jubair', ':...  \n",
       "4  ['narrated', 'by', 'ibn', \"'abbas\", ':', 'alla...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization (split into tokens)\n",
    "\n",
    "def word_tokenization(text):\n",
    "    text = word_tokenize(text.lower())\n",
    "    return \" \".join([word for word in str(text).split()])\n",
    "\n",
    "data['Text'] = data['Text'].apply(lambda text: word_tokenization(text))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e37703b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Volume_No</th>\n",
       "      <th>Chapter_No</th>\n",
       "      <th>Hadith_No</th>\n",
       "      <th>Chapter</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>narrated by umar bin alkhattab  i heard allah ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>narrated by aisha   the mother of the faithful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>narrated by aisha   the mother of the faithful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>narrated by said bin jubair  ibn abbas in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>narrated by ibn abbas  allah s apostle was the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Source  Volume_No  Chapter_No  Hadith_No     Chapter  \\\n",
       "0  Sahih Bukhari          1           1          1  Revelation   \n",
       "1  Sahih Bukhari          1           1          2  Revelation   \n",
       "2  Sahih Bukhari          1           1          3  Revelation   \n",
       "3  Sahih Bukhari          1           1          4  Revelation   \n",
       "4  Sahih Bukhari          1           1          5  Revelation   \n",
       "\n",
       "                                                Text  \n",
       "0  narrated by umar bin alkhattab  i heard allah ...  \n",
       "1  narrated by aisha   the mother of the faithful...  \n",
       "2  narrated by aisha   the mother of the faithful...  \n",
       "3  narrated by said bin jubair  ibn abbas in the ...  \n",
       "4  narrated by ibn abbas  allah s apostle was the...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing punctuations \n",
    "def remove_punctuations(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "    return text\n",
    "\n",
    "data['Text'] = data['Text'].apply(remove_punctuations)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7d771e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
      "Total numbers of stop words are \n",
      "179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ACER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Importing Nltk stopword package\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#Loading Stopwords into a list\n",
    "NLTK_stop_words_list=stopwords.words('english')\n",
    "print(NLTK_stop_words_list)\n",
    "print(\"Total numbers of stop words are \")\n",
    "print(len(NLTK_stop_words_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22a0410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1-Create stopwords list (removing sanad)\n",
    "custom_stopword_list=['narrated','narrator','umar','bin','alkhattab','abu','aisha','etc','ie','us','narrate','narrates','narrating','narration', \n",
    "                      'narrations','narrators','said','abbas','aas','abul','aba','amr','abdullah','huraira','ibn','jabir','jubair','alansari','musa',\n",
    "                      'abul','abulqasim','anas','ubada','assamit','alkhudri','sad','almarur','alahnaf','qais','albara','azib',\n",
    "                      'talha','ubaidullah','annuman','bashir','jamra','masud','abi','waqqas','jarir','ziyad',\n",
    "                      'ilaqa','malik','waqid','allaithi','abdurrahman','bakra','father','wail','muawiya','mahmud',\n",
    "                      'rabia','alaas','asma','mulaika','alansari','zaid','khalid','aljuhani','burda','alas','ali',\n",
    "                      'azzubair','salama','ashhubi','um','ammar','aswad','attufail','nafi','nuam','almujmir','tamim',\n",
    "                      'kuraib','usama','ata','yasar','aiyub','qatada','humran','urwa','uthman','affan','muhammad',\n",
    "                      'juraij','ubaid','umatiya','seereen','hamza','adi','hatim','almughira','shuba','bakr','yahya',\n",
    "                      'almazini','juhaifa','shihab','assaib','yazid','thabit','jafar','umaiya','addamri','suwaid',\n",
    "                      'alnuman','maimuna','amir','numan','qais','binti','bint','mihsin','hudhaifa','wail','sulaiman',\n",
    "                      'yasar','maimun','qilaba','hazim','mutim','alharith','almuntathir','hisham','hani','talib','umsalama',\n",
    "                      'ubai','kab','alqasim','alaswad','muadha','zainab','samura','jundub','juhaim','abza','imran','shaqiq',\n",
    "                      'alamash','husain','alkhuzai','dhar','almunkadir','murra','sahl','mughira','shuba','abdul','aziz','uqba',\n",
    "                      'shaddad','ishaq','maslama','ibrahim','siyah','dinar','mujahid','bara','itban','attaiyah','alaslami',\n",
    "                      'ikrima','alkhaulani','hassan','rafi','alsaib','abbad','aun','alubaid','busr','ghailan','azzuhri',\n",
    "                      'alghifar','alminhal','saiyar','hunaif','almahh','salim','khadij','almuzani','barza','malih',\n",
    "                      'abulminhal','qurra','humaid','isa','hafsa','mughaffal','almuzani','huwairith','buhaina','rabi',\n",
    "                      'assaidi','utba','khiyar','muadh','jabal','mamar','marwan','alhakam','mutarrif','musab','wahb','rifaa',\n",
    "                      'azzuraqi','ata','mabad','warrad','ashshaibani','abis','umm','salmanalfarsi','tawus','salman','umama',\n",
    "                      'fatima','almundhir','taghlib','hummaid','almiswar','makhrama','shuaib','althaqafi','masruq','namir',\n",
    "                      'sharik','addahhak','zahdam','raja','alutaridi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecb5ac53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['narrated', 'narrator', 'umar', 'bin', 'alkhattab', 'abu', 'aisha', 'etc', 'ie', 'us', 'narrate', 'narrates', 'narrating', 'narration', 'narrations', 'narrators', 'said', 'abbas', 'aas', 'abul', 'aba', 'amr', 'abdullah', 'huraira', 'ibn', 'jabir', 'jubair', 'alansari', 'musa', 'abul', 'abulqasim', 'anas', 'ubada', 'assamit', 'alkhudri', 'sad', 'almarur', 'alahnaf', 'qais', 'albara', 'azib', 'talha', 'ubaidullah', 'annuman', 'bashir', 'jamra', 'masud', 'abi', 'waqqas', 'jarir', 'ziyad', 'ilaqa', 'malik', 'waqid', 'allaithi', 'abdurrahman', 'bakra', 'father', 'wail', 'muawiya', 'mahmud', 'rabia', 'alaas', 'asma', 'mulaika', 'alansari', 'zaid', 'khalid', 'aljuhani', 'burda', 'alas', 'ali', 'azzubair', 'salama', 'ashhubi', 'um', 'ammar', 'aswad', 'attufail', 'nafi', 'nuam', 'almujmir', 'tamim', 'kuraib', 'usama', 'ata', 'yasar', 'aiyub', 'qatada', 'humran', 'urwa', 'uthman', 'affan', 'muhammad', 'juraij', 'ubaid', 'umatiya', 'seereen', 'hamza', 'adi', 'hatim', 'almughira', 'shuba', 'bakr', 'yahya', 'almazini', 'juhaifa', 'shihab', 'assaib', 'yazid', 'thabit', 'jafar', 'umaiya', 'addamri', 'suwaid', 'alnuman', 'maimuna', 'amir', 'numan', 'qais', 'binti', 'bint', 'mihsin', 'hudhaifa', 'wail', 'sulaiman', 'yasar', 'maimun', 'qilaba', 'hazim', 'mutim', 'alharith', 'almuntathir', 'hisham', 'hani', 'talib', 'umsalama', 'ubai', 'kab', 'alqasim', 'alaswad', 'muadha', 'zainab', 'samura', 'jundub', 'juhaim', 'abza', 'imran', 'shaqiq', 'alamash', 'husain', 'alkhuzai', 'dhar', 'almunkadir', 'murra', 'sahl', 'mughira', 'shuba', 'abdul', 'aziz', 'uqba', 'shaddad', 'ishaq', 'maslama', 'ibrahim', 'siyah', 'dinar', 'mujahid', 'bara', 'itban', 'attaiyah', 'alaslami', 'ikrima', 'alkhaulani', 'hassan', 'rafi', 'alsaib', 'abbad', 'aun', 'alubaid', 'busr', 'ghailan', 'azzuhri', 'alghifar', 'alminhal', 'saiyar', 'hunaif', 'almahh', 'salim', 'khadij', 'almuzani', 'barza', 'malih', 'abulminhal', 'qurra', 'humaid', 'isa', 'hafsa', 'mughaffal', 'almuzani', 'huwairith', 'buhaina', 'rabi', 'assaidi', 'utba', 'khiyar', 'muadh', 'jabal', 'mamar', 'marwan', 'alhakam', 'mutarrif', 'musab', 'wahb', 'rifaa', 'azzuraqi', 'ata', 'mabad', 'warrad', 'ashshaibani', 'abis', 'umm', 'salmanalfarsi', 'tawus', 'salman', 'umama', 'fatima', 'almundhir', 'taghlib', 'hummaid', 'almiswar', 'makhrama', 'shuaib', 'althaqafi', 'masruq', 'namir', 'sharik', 'addahhak', 'zahdam', 'raja', 'alutaridi', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
      "420\n"
     ]
    }
   ],
   "source": [
    "final_stopword_list = custom_stopword_list + NLTK_stop_words_list\n",
    "print(final_stopword_list)\n",
    "print(len(final_stopword_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79e764ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Volume_No</th>\n",
       "      <th>Chapter_No</th>\n",
       "      <th>Hadith_No</th>\n",
       "      <th>Chapter</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>heard allah apostle saying reward deeds depend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>mother faithful believers asked allah apostle ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>mother faithful believers commencement divine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>explanation statement allah move tongue concer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>allah apostle generous people used reach peak ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Source  Volume_No  Chapter_No  Hadith_No     Chapter  \\\n",
       "0  Sahih Bukhari          1           1          1  Revelation   \n",
       "1  Sahih Bukhari          1           1          2  Revelation   \n",
       "2  Sahih Bukhari          1           1          3  Revelation   \n",
       "3  Sahih Bukhari          1           1          4  Revelation   \n",
       "4  Sahih Bukhari          1           1          5  Revelation   \n",
       "\n",
       "                                                Text  \n",
       "0  heard allah apostle saying reward deeds depend...  \n",
       "1  mother faithful believers asked allah apostle ...  \n",
       "2  mother faithful believers commencement divine ...  \n",
       "3  explanation statement allah move tongue concer...  \n",
       "4  allah apostle generous people used reach peak ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing stopwords \n",
    "stops = set(final_stopword_list)\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join([word for word in str(text).split()\n",
    "                    if word not in stops])\n",
    "\n",
    "data['Text'] = data['Text'].apply(lambda text: remove_stopwords(text))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e918b379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Volume_No</th>\n",
       "      <th>Chapter_No</th>\n",
       "      <th>Hadith_No</th>\n",
       "      <th>Chapter</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>heard allah apostl say reward deed depend upon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>mother faith believ ask allah apostl allah apo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>mother faith believ commenc divin inspir allah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>explan statement allah move tongu concern qura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>allah apostl gener peopl use reach peak genero...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Source  Volume_No  Chapter_No  Hadith_No     Chapter  \\\n",
       "0  Sahih Bukhari          1           1          1  Revelation   \n",
       "1  Sahih Bukhari          1           1          2  Revelation   \n",
       "2  Sahih Bukhari          1           1          3  Revelation   \n",
       "3  Sahih Bukhari          1           1          4  Revelation   \n",
       "4  Sahih Bukhari          1           1          5  Revelation   \n",
       "\n",
       "                                                Text  \n",
       "0  heard allah apostl say reward deed depend upon...  \n",
       "1  mother faith believ ask allah apostl allah apo...  \n",
       "2  mother faith believ commenc divin inspir allah...  \n",
       "3  explan statement allah move tongu concern qura...  \n",
       "4  allah apostl gener peopl use reach peak genero...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming (valid stems)\n",
    "porter = PorterStemmer()\n",
    "def stemming(text):\n",
    "    token_words=word_tokenize(text)\n",
    "    token_words\n",
    "    stem_sentence=[]\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(porter.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)\n",
    "\n",
    "data['Text'] = data['Text'].apply(lambda text: stemming(text))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8f434f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Volume_No</th>\n",
       "      <th>Chapter_No</th>\n",
       "      <th>Hadith_No</th>\n",
       "      <th>Chapter</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>heard allah apostl say reward deed depend upon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>mother faith believ ask allah apostl allah apo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>mother faith believ commenc divin inspir allah...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>explan statement allah move tongu concern qura...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sahih Bukhari</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>allah apostl gener peopl use reach peak genero...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Source  Volume_No  Chapter_No  Hadith_No     Chapter  \\\n",
       "0  Sahih Bukhari          1           1          1  Revelation   \n",
       "1  Sahih Bukhari          1           1          2  Revelation   \n",
       "2  Sahih Bukhari          1           1          3  Revelation   \n",
       "3  Sahih Bukhari          1           1          4  Revelation   \n",
       "4  Sahih Bukhari          1           1          5  Revelation   \n",
       "\n",
       "                                                Text  Label  \n",
       "0  heard allah apostl say reward deed depend upon...      0  \n",
       "1  mother faith believ ask allah apostl allah apo...      0  \n",
       "2  mother faith believ commenc divin inspir allah...      0  \n",
       "3  explan statement allah move tongu concern qura...      0  \n",
       "4  allah apostl gener peopl use reach peak genero...      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary with the label codification (Classify hadith text by chapter)\n",
    "# Example: Revelation = 0, Belief = 1, Knowledge = 2\n",
    "\n",
    "data['Label'] = data['Chapter'].factorize()[0]\n",
    "from io import StringIO\n",
    "category_id_df = data[['Chapter', 'Label']].drop_duplicates().sort_values('Label')\n",
    "category_to_id = dict(category_id_df.values)\n",
    "id_to_category = dict(category_id_df[['Label', 'Chapter']].values)\n",
    "\n",
    "data.head()\n",
    "#data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63798021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "\n",
    "X = data['Text']\n",
    "y = data['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7b752ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(844, 300)\n",
      "(211, 300)\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering (TF-IDF vectors)\n",
    "# fitted and then transformed the training set, but only transformed the test set\n",
    "# Parameter election\n",
    "ngram_range = (1,2)\n",
    "min_df = 10\n",
    "max_df = 1.\n",
    "max_features = 300\n",
    "\n",
    "tfidf = TfidfVectorizer(encoding='utf-8',\n",
    "                        ngram_range=ngram_range,\n",
    "                        stop_words=None,\n",
    "                        lowercase=False,\n",
    "                        max_df=max_df,\n",
    "                        min_df=min_df,\n",
    "                        max_features=max_features,\n",
    "                        norm='l2',\n",
    "                        sublinear_tf=True)\n",
    "                        \n",
    "features_train = tfidf.fit_transform(X_train).toarray()\n",
    "labels_train = y_train\n",
    "print(features_train.shape)\n",
    "\n",
    "features_test = tfidf.transform(X_test).toarray()\n",
    "labels_test = y_test\n",
    "print(features_test.shape)\n",
    "# Answer: each of 844 hadith texts (train) is represented by 300 features, each of 211 hadith texts (test) is represented by 300 features\n",
    "# representing the TF-IDF score for different unigrams and bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1310043c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 'Ablution (Wudu')' Category:\n",
      "  . Most correlated unigrams:\n",
      ". wet\n",
      ". answer\n",
      ". wash\n",
      ". water\n",
      ". ablut\n",
      "  . Most correlated bigrams:\n",
      ". prophet ask\n",
      ". perform ablut\n",
      "\n",
      "# 'Ablution with dust' Category:\n",
      "  . Most correlated unigrams:\n",
      ". hand\n",
      ". back\n",
      ". suffici\n",
      ". statement\n",
      ". earth\n",
      "  . Most correlated bigrams:\n",
      ". allah apostl\n",
      ". prophet use\n",
      "\n",
      "# 'Bathing (Ghusl)' Category:\n",
      "  . Most correlated unigrams:\n",
      ". pot\n",
      ". bodi\n",
      ". wash\n",
      ". pour\n",
      ". bath\n",
      "  . Most correlated bigrams:\n",
      ". take bath\n",
      ". pour water\n",
      "\n",
      "# 'Belief' Category:\n",
      "  . Most correlated unigrams:\n",
      ". islam\n",
      ". muslim\n",
      ". reward\n",
      ". religion\n",
      ". faith\n",
      "  . Most correlated bigrams:\n",
      ". allah allah\n",
      ". worship allah\n",
      "\n",
      "# 'Call to Prayer (Adhaan)' Category:\n",
      "  . Most correlated unigrams:\n",
      ". congreg\n",
      ". lead\n",
      ". adhan\n",
      ". pronounc\n",
      ". iqama\n",
      "  . Most correlated bigrams:\n",
      ". lead prayer\n",
      ". pronounc adhan\n",
      "\n",
      "# 'Characteristics of Prayer' Category:\n",
      "  . Most correlated unigrams:\n",
      ". rais\n",
      ". rak\n",
      ". prostrat\n",
      ". bow\n",
      ". takbir\n",
      "  . Most correlated bigrams:\n",
      ". rais head\n",
      ". say takbir\n",
      "\n",
      "# 'Dua' for Rain (Istisqaa)' Category:\n",
      "  . Most correlated unigrams:\n",
      ". pleas\n",
      ". turn\n",
      ". bless\n",
      ". invok\n",
      ". rain\n",
      "  . Most correlated bigrams:\n",
      ". apostl allah\n",
      ". invok allah\n",
      "\n",
      "# 'Eclipses' Category:\n",
      "  . Most correlated unigrams:\n",
      ". prolong\n",
      ". lifetim\n",
      ". sign\n",
      ". sun\n",
      ". eclips\n",
      "  . Most correlated bigrams:\n",
      ". finish prayer\n",
      ". invok allah\n",
      "\n",
      "# 'Fear Prayer' Category:\n",
      "  . Most correlated unigrams:\n",
      ". someth\n",
      ". stand\n",
      ". second\n",
      ". muslim\n",
      ". set\n",
      "  . Most correlated bigrams:\n",
      ". asr prayer\n",
      ". peopl prayer\n",
      "\n",
      "# 'Friday Prayer' Category:\n",
      "  . Most correlated unigrams:\n",
      ". pulpit\n",
      ". khutba\n",
      ". pbuh\n",
      ". friday\n",
      ". jumua\n",
      "  . Most correlated bigrams:\n",
      ". prophet pbuh\n",
      ". apostl pbuh\n",
      "\n",
      "# 'Knowledge' Category:\n",
      "  . Most correlated unigrams:\n",
      ". kill\n",
      ". tree\n",
      ". religi\n",
      ". knowledg\n",
      ". hadith\n",
      "  . Most correlated bigrams:\n",
      ". apostl repli\n",
      ". prophet ask\n",
      "\n",
      "# 'Menstrual Periods' Category:\n",
      "  . Most correlated unigrams:\n",
      ". got\n",
      ". period\n",
      ". hajj\n",
      ". blood\n",
      ". mens\n",
      "  . Most correlated bigrams:\n",
      ". take bath\n",
      ". repli ye\n",
      "\n",
      "# 'Prayer (Salat)' Category:\n",
      "  . Most correlated unigrams:\n",
      ". kaba\n",
      ". singl\n",
      ". garment\n",
      ". mosqu\n",
      ". spit\n",
      "  . Most correlated bigrams:\n",
      ". asr prayer\n",
      ". prophet pray\n",
      "\n",
      "# 'Prayer Hall (Sutra)' Category:\n",
      "  . Most correlated unigrams:\n",
      ". bilal\n",
      ". wall\n",
      ". kaba\n",
      ". pass\n",
      ". front\n",
      "  . Most correlated bigrams:\n",
      ". prophet use\n",
      ". use pray\n",
      "\n",
      "# 'Prostration During Recital of Qur'an' Category:\n",
      "  . Most correlated unigrams:\n",
      ". perform\n",
      ". stone\n",
      ". friday\n",
      ". recit\n",
      ". prostrat\n",
      "  . Most correlated bigrams:\n",
      ". fajr prayer\n",
      ". isha prayer\n",
      "\n",
      "# 'Revelation' Category:\n",
      "  . Most correlated unigrams:\n",
      ". make\n",
      ". statement\n",
      ". quran\n",
      ". angel\n",
      ". reveal\n",
      "  . Most correlated bigrams:\n",
      ". apostl repli\n",
      ". apostl allah\n",
      "\n",
      "# 'Shortening Prayers (At-Taqseer)' Category:\n",
      "  . Most correlated unigrams:\n",
      ". rakat\n",
      ". three\n",
      ". offer\n",
      ". direct\n",
      ". journey\n",
      "  . Most correlated bigrams:\n",
      ". prophet pbuh\n",
      ". use offer\n",
      "\n",
      "# 'The Two Festivals (Eids)' Category:\n",
      "  . Most correlated unigrams:\n",
      ". deliv\n",
      ". khutba\n",
      ". slaughter\n",
      ". sacrific\n",
      ". id\n",
      "  . Most correlated bigrams:\n",
      ". offer prayer\n",
      ". deliv khutba\n",
      "\n",
      "# 'Times of the Prayer' Category:\n",
      "  . Most correlated unigrams:\n",
      ". zuhr\n",
      ". set\n",
      ". still\n",
      ". sun\n",
      ". asr\n",
      "  . Most correlated bigrams:\n",
      ". prayer till\n",
      ". asr prayer\n",
      "\n",
      "# 'Witr Prayer' Category:\n",
      "  . Most correlated unigrams:\n",
      ". rakat\n",
      ". recit\n",
      ". night\n",
      ". month\n",
      ". fajr\n",
      "  . Most correlated bigrams:\n",
      ". two rakat\n",
      ". fajr prayer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use the Chi squared test in order to see what unigrams and bigrams are most correlated with each category\n",
    "\n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "\n",
    "for Chapter, Label in sorted(category_to_id.items()):\n",
    "    features_chi2 = chi2(features_train, labels_train == Label)\n",
    "    indices = np.argsort(features_chi2[0])\n",
    "    feature_names = np.array(tfidf.get_feature_names_out())[indices]\n",
    "    unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "    bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "    print(\"# '{}' Category:\".format(Chapter))\n",
    "    print(\"  . Most correlated unigrams:\\n. {}\".format('\\n. '.join(unigrams[-5:])))\n",
    "    print(\"  . Most correlated bigrams:\\n. {}\".format('\\n. '.join(bigrams[-2:])))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7d2ab1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the files we'll need in the next steps\n",
    "\n",
    "# X_train\n",
    "with open('X_train.pickle', 'wb') as output:\n",
    "    pickle.dump(X_train, output)\n",
    "    \n",
    "# X_test    \n",
    "with open('X_test.pickle', 'wb') as output:\n",
    "    pickle.dump(X_test, output)\n",
    "    \n",
    "# y_train\n",
    "with open('y_train.pickle', 'wb') as output:\n",
    "    pickle.dump(y_train, output)\n",
    "    \n",
    "# y_test\n",
    "with open('y_test.pickle', 'wb') as output:\n",
    "    pickle.dump(y_test, output)\n",
    "    \n",
    "# data\n",
    "with open('data.pickle', 'wb') as output:\n",
    "    pickle.dump(data, output)\n",
    "    \n",
    "# features_train\n",
    "with open('features_train.pickle', 'wb') as output:\n",
    "    pickle.dump(features_train, output)\n",
    "\n",
    "# labels_train\n",
    "with open('labels_train.pickle', 'wb') as output:\n",
    "    pickle.dump(labels_train, output)\n",
    "\n",
    "# features_test\n",
    "with open('features_test.pickle', 'wb') as output:\n",
    "    pickle.dump(features_test, output)\n",
    "    \n",
    "# labels_test\n",
    "with open('labels_test.pickle', 'wb') as output:\n",
    "    pickle.dump(labels_test, output)\n",
    "    \n",
    "# TF-IDF object\n",
    "with open('tfidf.pickle', 'wb') as output:\n",
    "    pickle.dump(tfidf, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
