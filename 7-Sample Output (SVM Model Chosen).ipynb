{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4cc1f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT LIBRARIES\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import punkt\n",
    "from nltk.corpus.reader import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ace0074",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAINED MODEL\n",
    "path_models = \"\"\n",
    "\n",
    "# SVM\n",
    "path_svm = path_models + 'svc_0.pickle'\n",
    "with open(path_svm, 'rb') as data:\n",
    "    svc_model = pickle.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fdf9e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF object\n",
    "path_tfidf = \"tfidf.pickle\"\n",
    "with open(path_tfidf, 'rb') as data:\n",
    "    tfidf = pickle.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6649d2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LABEL MAPPING DICTIONARY\n",
    "Label = {\n",
    "    'Revelation': 0,\n",
    "    'Belief': 1,\n",
    "    'Knowledge': 2,\n",
    "    \"Ablution (Wudu')\" : 3,\n",
    "    'Bathing (Ghusl)' : 4,\n",
    "    'Mestrual Periods' : 5,\n",
    "    'Ablution with dust' : 6,\n",
    "    'Prayer (Salat)' : 7,\n",
    "    'Prayer Hall (Sutra)' : 8,\n",
    "    'Times of the Prayer' : 9,\n",
    "    'Call to Prayer (Adhaan)' : 10,\n",
    "    'Characteristics of Prayer' : 11,\n",
    "    'Friday Prayer' : 12,\n",
    "    'Fear Prayer' : 13,\n",
    "    'The Two Festivals (Eids)' : 14,\n",
    "    'Witr Prayer' : 15,\n",
    "    \"Dua' for Rain (Istisqaa)\" : 16,\n",
    "    'Eclipses' : 17,\n",
    "    \"Prostration During Recital of Qur'an\" : 18,\n",
    "    \"Shortening Prayers (At-Taqseer)\" : 19   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "649e3a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE ENGINEERING WORKFLOW\n",
    "punctuation_signs = list(\"?:!.,;\")\n",
    "stop_words = list(stopwords.words('english'))\n",
    "\n",
    "def create_features_from_text(text):\n",
    "    \n",
    "    # Dataframe creation\n",
    "    lemmatized_text_list = []\n",
    "    df = pd.DataFrame(columns=['Text'])\n",
    "    df.loc[0] = text\n",
    "    df['Text'] = df['Text'].str.replace(\"\\r\", \" \")\n",
    "    df['Text'] = df['Text'].str.replace(\"\\n\", \" \")\n",
    "    df['Text'] = df['Text'].str.replace(\"    \", \" \")\n",
    "    df['Text'] = df['Text'].str.replace('\"', '')\n",
    "    df['Text'] = df['Text'].str.lower()\n",
    "    df['Text'] = df['Text']\n",
    "    for punct_sign in punctuation_signs:\n",
    "        df['Text'] = df['Text'].str.replace(punct_sign, '')\n",
    "    df['Text'] = df['Text'].str.replace(\"'s\", \"\")\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_list = []\n",
    "    text = df.loc[0]['Text']\n",
    "    text_words = text.split(\" \")\n",
    "    for word in text_words:\n",
    "        lemmatized_list.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n",
    "    lemmatized_text = \" \".join(lemmatized_list)    \n",
    "    lemmatized_text_list.append(lemmatized_text)\n",
    "    df['Text'] = lemmatized_text_list\n",
    "    df['Text'] = df['Text']\n",
    "    for stop_word in stop_words:\n",
    "        regex_stopword = r\"\\b\" + stop_word + r\"\\b\"\n",
    "        df['Text'] = df['Text'].str.replace(regex_stopword, '')\n",
    "    df = df['Text']\n",
    "    \n",
    "    # TF-IDF\n",
    "    features = tfidf.transform(df).toarray()\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da41506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function that tells us the chapter category given the label:\n",
    "def get_category_name(category_id):\n",
    "    for category, id_ in Label.items():    \n",
    "        if id_ == category_id:\n",
    "            return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c189a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function that includes the whole process:\n",
    "def predict_from_text(text):\n",
    "    \n",
    "    # Predict using the input model\n",
    "    prediction_svc = svc_model.predict(create_features_from_text(text))[0]\n",
    "    #prediction_svc_proba = svc_model.predict_proba(create_features_from_text(text))[0]\n",
    "    \n",
    "    # Return result\n",
    "    category_svc = get_category_name(prediction_svc)\n",
    "    \n",
    "    print(\"The predicted category using the SVM model is %s.\" %(category_svc) )\n",
    "    #print(\"The conditional probability is: %a\" %(prediction_svc_proba.max()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4292aa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEXT PREDICTION\n",
    "text = \"\"\"\n",
    "\n",
    "Narrated by 'Umar bin Al-Khattab:  I heard Allah's Apostle saying, \"The reward of deeds depends upon the intentions and every person will get the reward according to what he has intended. So whoever emigrated for worldly benefits or for a woman to marry, his emigration was for what he emigrated for.\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4d286f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted category using the SVM model is Knowledge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-23440054f875>:18: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  df['Text'] = df['Text'].str.replace(punct_sign, '')\n",
      "<ipython-input-11-23440054f875>:32: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Text'] = df['Text'].str.replace(regex_stopword, '')\n"
     ]
    }
   ],
   "source": [
    "predict_from_text(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
